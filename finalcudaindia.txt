
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <ctime>
#include <stdio.h>
#include <vector>
#include <limits>
#include <algorithm>

#include <Windows.h>

cudaError_t sortWithCuda(int *a, size_t size, float* time);

typedef long long int64; 
typedef unsigned long long uint64;


__global__ void swapOnKernel(int *a, int size)
{
    int i = blockDim.x * blockIdx.x + threadIdx.x * 2;
	int cacheFirst;
	int cacheSecond;
	int cacheThird;

	int cacheFirst1;
	int cacheSecond1;
	int cacheThird1;

	int counter = (size * 2) -1;

    for (int j = 0; j < size/2 + 1; j++) {
       // right pass = amking first elemt smallest
		if (counter - 1 < 0) {
			cacheFirst1 = a[i];
			cacheSecond1 = a[i + 1];

			if (cacheFirst1 < cacheSecond1) {
				int temp1 = cacheFirst1;
				a[counter] = cacheSecond1;
				cacheSecond1 = a[counter - 1] = temp1;
			}
		}


		if (counter - 2 < 0) {
			cacheThird1 = a[counter - 2];
			if (cacheSecond < cacheThird) {
				int temp1 = cacheSecond1;
				a[counter - 1] = cacheThird1;
				a[counter - 2] = temp1;
			}
		}
		counter--;
//left pass making last element largest
	    if(i+1 < size) {
		    cacheFirst = a[i];
		    cacheSecond = a[i+1];

		    if(cacheFirst > cacheSecond) {
			    int temp = cacheFirst;
			    a[i] = cacheSecond;
			    cacheSecond = a[i+1] = temp;
		    }
	    }

	    if(i+2 < size) {
		    cacheThird = a[i+2];
		    if(cacheSecond > cacheThird) {
			    int temp = cacheSecond;
			    a[i+1] = cacheThird;
			    a[i+2] = temp;
		    }
	    }

        __syncthreads();
    }

}



int main()
{
	srand((unsigned)time(0)); 
    long arraySize = 100000;

	// Create vector and fill it with values
	std::vector<int> a(arraySize);
	
	printf("\n array size is %ld ", arraySize);

	FILE* myFile;
	myFile = fopen("data.txt", "r");

	//read file into array
	//int numberArray[16];
	int i;

	if (myFile == NULL) {
		printf("Error Reading File\n");
		exit(0);
	}

	for (i = 0; i < arraySize; i++) {
		fscanf(myFile, "%d,", &a[i]);
	}

	for (i = 0; i < arraySize; i++) {
		//printf("%d, ", a[i]);
	}

	printf("\nOMGGGG\n");
	fclose(myFile);
	std::vector<int> b(a);
	
	float time = 0.0;
    // Swap elements in parallel.
    cudaError_t cudaStatus = sortWithCuda(&a[0], a.size(), &time);

	if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "sortWithCuda failed!");
        return 1;
    }

	bool sortingSuccessful = true;
	for (int i = 0; i < a.size()-1; ++i) {
		if (a[i] > a[i+1]) {
			//sortingSuccessful = false;
			//break;
		}
		//printf("%d, ", a[i]);
	}
	//printf("\n");

	printf ("Time for the GPU: %f ms\n", time/CLOCKS_PER_SEC);

	if(!sortingSuccessful) {
		printf("Sorting failed.\n");
	}

	


    // cudaDeviceReset must be called before exiting in order for profiling and
    // tracing tools such as Parallel Nsight and Visual Profiler to show complete traces.
    cudaStatus = cudaDeviceReset();
    if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "cudaDeviceReset failed!");
        return 1;
    }

	//getchar();

    return 0;
}


__host__ cudaError_t sortWithCuda(int *a, size_t size, float* time)
{
    int *dev_a = 0;
    cudaError_t cudaStatus;

    // Choose which GPU to run on, change this on a multi-GPU system.
    cudaStatus = cudaSetDevice(0);
    if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "cudaSetDevice failed!  Do you have a CUDA-capable GPU installed?");
        goto Error;
    }

    // Allocate GPU buffers for one vectors.
    cudaStatus = cudaMalloc((void**)&dev_a, size * sizeof(int));
    if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "cudaMalloc failed!");
        goto Error;
    }

     // Copy input vectors from host memory to GPU buffers.
    cudaStatus = cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice);
    if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "cudaMemcpy failed!");
        goto Error;
    }

	// Create timer
	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);

	cudaEventRecord(start, 0);
    // Launch a kernel on the GPU with one thread for each element.

    swapOnKernel<<<size/512, 512>>>(dev_a, size);

    cudaEventRecord(stop, 0);
	cudaEventSynchronize(stop);
	cudaEventElapsedTime(time, start, stop);

    // Copy output vector from GPU buffer to host memory.
    cudaStatus = cudaMemcpy(a, dev_a, size * sizeof(int), cudaMemcpyDeviceToHost);
    if (cudaStatus != cudaSuccess) {
        fprintf(stderr, "cudaMemcpy failed!");
        goto Error;
    }

Error:
    cudaFree(dev_a);
    
    return cudaStatus;
}